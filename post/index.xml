<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts | Academic</title>
    <link>https://zhiyuanpeng.github.io/post/</link>
      <atom:link href="https://zhiyuanpeng.github.io/post/index.xml" rel="self" type="application/rss+xml" />
    <description>Posts</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Thu, 13 May 2021 13:59:30 -0700</lastBuildDate>
    <image>
      <url>https://zhiyuanpeng.github.io/media/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_512x512_fill_lanczos_center_2.png</url>
      <title>Posts</title>
      <link>https://zhiyuanpeng.github.io/post/</link>
    </image>
    
    <item>
      <title>Advanced Indexing of Array and Tensor</title>
      <link>https://zhiyuanpeng.github.io/post/array-indexing/</link>
      <pubDate>Thu, 13 May 2021 13:59:30 -0700</pubDate>
      <guid>https://zhiyuanpeng.github.io/post/array-indexing/</guid>
      <description>&lt;p&gt;Explore the advanced indexing of Numpy array and Pytorch tensor&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import numpy as np
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;x = np.array([[ 0,  1,  2],
              [ 3,  4,  5],
              [ 6,  7,  8],
              [ 9, 10, 11]])
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;rows = np.array([[0, 0],
                 [3, 3]])
columns = np.array([[0, 2],
                    [0, 2]])
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;x[rows, columns]
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;array([[ 0,  2],
       [ 9, 11]])
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The result stores the values located in (0,0), (0,2), (3,0), (3,2). Also the result has the same shape as one of the input indexings. Here rows is 2&lt;em&gt;2, so, the result is also 2&lt;/em&gt;2.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;x = np.array([[1, 2], [3, 4], [5, 6]])
x[[0, 1, 2], [0, 1, 0]]
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;array([1, 4, 5])
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;In the example above, the input dimension is 1*3, so the result is also 1*3.
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Pytorch tensor has the samilar indexing method as numpy array. Let&amp;rsquo;s do some experiments.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import torch
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;x_tensor = torch.tensor([[1,2], [3,4], [5,6]])
x_tensor[[0,1,2],[0,1,0]]
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;tensor([1, 4, 5])
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;x_tensor = torch.tensor([[ 0,  1,  2],
                         [ 3,  4,  5],
                         [ 6,  7,  8],
                         [ 9, 10, 11]])
x_tensor[rows, columns]
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;tensor([[ 0,  2],
        [ 9, 11]])
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Representation of Undirected Graph Models</title>
      <link>https://zhiyuanpeng.github.io/post/representation-of-undirected-graph-models/</link>
      <pubDate>Thu, 13 May 2021 13:59:30 -0700</pubDate>
      <guid>https://zhiyuanpeng.github.io/post/representation-of-undirected-graph-models/</guid>
      <description>&lt;style&gt;
body {
text-align: justify}
&lt;/style&gt;
&lt;p&gt;Koller/Friedman&amp;rsquo;s book &lt;strong&gt;Probabilistic Graphical Models: Principles and Techniques&lt;/strong&gt; &lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt; (PGM) is the most exhaustive book I have found for PGM, however, there are many definitions, theorems and mathematics within it which make the book hard to understand. When I read chapter 4 of this book, I meet two questions: one is why the potential functions are defined on cliques, another is why the d-separation works. For the first question, I didn&amp;rsquo;t find a good answer from Koller/Friedman&amp;rsquo;s book, but, I found Micheal I. Jordan&amp;rsquo;s unfinished book &lt;strong&gt;An Introduction to Probabilistic Graphical Model&lt;/strong&gt; &lt;sup id=&#34;fnref:2&#34;&gt;&lt;a href=&#34;#fn:2&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;2&lt;/a&gt;&lt;/sup&gt; gives some institutions of why we do it like that. For the second one, Koller/Friedman&amp;rsquo;s book defines the d-separation in definition 4.9 and proves the soundness in theorem 4.1. When I first read theorem 4.1, I didn&amp;rsquo;t understand why the proof of theorem 4.1 could prove the soundness of definition 4.9. I got it after I read that part several times and I will share what I learned in this post.&lt;/p&gt;
&lt;h1 id=&#34;prerequisites&#34;&gt;Prerequisites&lt;/h1&gt;
&lt;h2 id=&#34;some-important-concepts&#34;&gt;Some Important Concepts&lt;/h2&gt;
&lt;p&gt;If you feel Koller/Friedman&amp;rsquo;s PGM difficult to digest, you may not familiar with some concepts, so, we first clarify some concepts that I did not know when I first read this book:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;completeness: An axiom system is complete if all valid statements can be derived.&lt;/li&gt;
&lt;li&gt;soundness: An axiom system is sound if only valid statements can be derived.&lt;/li&gt;
&lt;li&gt;satisfiability: We say that a truth assignment $I$ satisfies a formula $\varphi$ if $\varphi[I]=\mathrm{T} ;$ we write this as $I \models \varphi$. A formula $\varphi$ is satisfiable if there exists a truth assignment $I$ such that $I \models \varphi$; otherwise $\varphi$ is unsatisfiable.&lt;/li&gt;
&lt;li&gt;validity: A formula $\varphi$ is valid (or a tautology) if for all a truth assignments $I, I \models \varphi$.&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;proof-of-exercise-25&#34;&gt;Proof of Exercise 2.5&lt;/h2&gt;
&lt;p&gt;In Koller/Friedman&amp;rsquo;s PGM book, the conclusion of exercise 2.5 is directly used to prove other theorems, but no proof is given. I googled this answer on the Internet, luckily, I found it and the proof is right in my view.&lt;/p&gt;
&lt;p&gt;Exercise 2.5:&lt;/p&gt;
&lt;p&gt;Let $X, Y, Z$ be three disjoint subsets of random variables. We say $X$ and $Y$ are conditionally independent given $Z$ if and only if&lt;/p&gt;
&lt;p&gt;$$
\mathbb P_{X, Y \mid Z}(x, y \mid z)=\mathbb P_{X \mid Z}(x \mid z) \mathbb P_{Y \mid Z}(y \mid z)
$$&lt;/p&gt;
&lt;p&gt;Show that $X$ and $Y$ are conditionally independent given $Z$ if and only if the joint distribution for the three subsets of random variables factors in the following form:&lt;/p&gt;
&lt;p&gt;$$
\mathbb P_{X, Y, Z}(x, y, \mid z)=h(x, z) g(y, z))
$$&lt;/p&gt;
&lt;p&gt;Solution:&lt;/p&gt;
&lt;p&gt;Fist, we proof if $X$ and $Y$ are conditionally independent given $Z$, we can get $\mathbb P_{X, Y, Z}(x, y, \mid z)=h(x, z) g(y, z))$ as follows:&lt;/p&gt;
&lt;p&gt;$$
\begin{aligned}
\mathbb P_{X, Y, Z}(x, y, z) &amp;amp;= \mathbb P_{Z}(z) \mathbb P_{X, Y | Z}(x, y | z) \\&lt;br&gt;
&amp;amp;=\mathbb P_{Z}(z) \mathbb P_{X | Z}(x | z) \mathbb P_{Y | Z}(y | z) \\&lt;br&gt;
&amp;amp;=h(x, z) g(y, z)
\end{aligned}
$$&lt;/p&gt;
&lt;p&gt;where we choose $h(x, z)=\mathbb P_{X \mid Z}(x \mid z)$ and $g(y, z) = \mathbb P_{Y \mid Z}(y \mid z) \mathbb P_{Z}(z)$&lt;/p&gt;
&lt;p&gt;Then, we proof that if we can write $\mathbb P_{X, Y, Z}(x, y, z)$ in this form: $h(x, z) g(y, z))$, we can get $\mathbb P_{X, Y \mid Z}(x, y \mid z)=\mathbb P_{X \mid Z}(x \mid z) \mathbb P_{Y \mid Z}(y \mid z)$:&lt;/p&gt;
&lt;p&gt;$$
\begin{aligned}
\mathbb P_{X, Y \mid Z}(z, y \mid z) &amp;amp;=\frac{\mathbb P_{X, Y, Z}(x, y, z)}{\sum_{x, y} \mathbb P_{X, Y, Z}(x, y, z)} \\&lt;br&gt;
&amp;amp;=\frac{h(x, z) g(y, z)}{\sum_{x, y} h(x, z) g(y, z)} \\&lt;br&gt;
&amp;amp;=\frac{h(x, z)}{h_{1}(z)} \frac{g(y, z)}{ g_{1}(z)} \\&lt;br&gt;
&amp;amp;=\mathbb P_{X \mid Z}(x \mid z) \mathbb P_{Y \mid Z}(y \mid z)
\end{aligned}
$$&lt;/p&gt;
&lt;h2 id=&#34;definition-44&#34;&gt;Definition 4.4&lt;/h2&gt;
&lt;p&gt;We say that a distribution factorizes over a Markov network $\mathcal{H}$ if each $\boldsymbol{D}_{k}(k=1, \ldots, K)$ is a complete subgraph of $\mathcal{H}$.&lt;/p&gt;
&lt;h2 id=&#34;gibbs-distribution&#34;&gt;Gibbs Distribution&lt;/h2&gt;
&lt;p&gt;A distribution $P_{\Phi}$ is a Gibbs distribution parameterized by a set of factors $\Phi=\left\{\phi_{1}\left(\boldsymbol{D}_{1}\right), \ldots, \phi_{K}\left(\boldsymbol{D}_{K}\right)\right\}$ if it is defined as follows:
$$
P_{\Phi}\left(X_{1}, \ldots, X_{n}\right)=\frac{1}{Z} \tilde{P}_{\Phi}\left(X_{1}, \ldots, X_{n}\right)
$$
where
$$
\tilde{P}_{\Phi}\left(X_{1}, \ldots, X_{n}\right)=\phi_{1}\left(\boldsymbol{D}_{1}\right) \times \phi_{2}\left(\boldsymbol{D}_{2}\right) \times \cdots \times \phi_{m}\left(\boldsymbol{D}_{m}\right)
$$
is an unnormalized measure and
$$
Z=\sum_{X_{.}} \tilde{P}_{\Phi}\left(X_{1}, \ldots, X_{n}\right)
$$&lt;/p&gt;
&lt;p&gt;If we say a Gibbs distribution which factorizes over a Markov network, each factor in this Gibbs distribution is over a clique or complete subgraph.&lt;/p&gt;
&lt;h2 id=&#34;definition-48&#34;&gt;Definition 4.8&lt;/h2&gt;
&lt;p&gt;Let $\mathcal{H}$ be a Markov network structure, and let $X_{1}-\ldots-X_{k}$ be a path in $\mathcal{H}$. Let $\boldsymbol{Z} \subseteq \mathcal{X}$ be a set of observed variables. The path $X_{1}-\ldots-X_{k}$ is active given $\boldsymbol{Z}$ if none of the $X_{i}$ &amp;rsquo;s, $i=1, \ldots, k$, is in $Z$.&lt;/p&gt;
&lt;h1 id=&#34;why-udg-is-defined-on-cliques&#34;&gt;Why UDG is defined on cliques?&lt;/h1&gt;
&lt;p&gt;$A&amp;ndash;B&amp;ndash;C$&lt;/p&gt;
&lt;p&gt;From the graph above, we can get $A \bot C \mid B$, so, we don&amp;rsquo;t want $A$ and $C$ in the same potential function because they are independent if $B$ is given. We notice that there is no edge connecting $A$ and $C$ directly, so, we may have an intuition that nodes that are not connected to each other should not be included in the same potential function. This is the intuition why UDG is defined on cliques. We use potential functions to measure the relationship among nodes within the same clique, not the conditional probability or marginal probability. For instance, we can use the chain rule to write the distribution $P$ factorizing over the graph above like this: $P = P(A)P(B \mid A)P(C \mid B)$. If you push $P$ into two factors, you may select one of the two forms: $P = P(A,B)P(C \mid B)$ and $P = P(B, C)P(A \mid B)$. Don&amp;rsquo;t forget that our distribution defined on UDG can be factorized like this $P = \Phi(A, B)\Phi(B,C)$. Then, we can get the conclusion that not all the potential functions are marginal probabilities or conditional probabilities. In one word, potential functions are not probabilities. How can we make sure the distribution consisting of potential functions equals 1 if we summarize all the variables within the distribution? We need a normalizer $\mathcal{Z}$. From definition 4.4 and the definition of Gibbs distribution, we know that we can use a Gibbs distribution which factorizes over the Markov network to represent the distribution expressed by the Markov network.&lt;/p&gt;
&lt;p&gt;Koller/Firedman says in the PGM book &amp;ldquo;if we define the UDG on cliques, we will not violate the independence assumptions induced by the network structure&amp;rdquo;. In my view, the authors here want to say that if we use the Gibbs distribution which factorizes over the Markov network to represent the distribution expressed by the network, we can prove the theorem 4.1 which also proves the soundness of the d-separation which is the independence assumptions induced by the network.&lt;/p&gt;
&lt;h1 id=&#34;why-d-seperation-works&#34;&gt;Why D-seperation works?&lt;/h1&gt;
&lt;p&gt;Definition 4.9 defines the d-separation of UDG. The proof of definition 4.9 will answer this question.&lt;/p&gt;
&lt;p&gt;Definition 4.9:&lt;/p&gt;
&lt;p&gt;We say that a set of nodes $\boldsymbol{Z}$ separates $\boldsymbol{X}$ and $\boldsymbol{Y}$ in $\mathcal{H}$, denoted $\operatorname{sep}_{\mathcal{H}}(\boldsymbol{X} ; \boldsymbol{Y} \mid \boldsymbol{Z})$, if there is no active path between any node $X \in X$ and $Y \in \boldsymbol{Y}$ given $\boldsymbol{Z}$. We define the global independencies associated with $\mathcal{H}$ to be:&lt;/p&gt;
&lt;p&gt;$$
\mathcal{I}(\mathcal{H})=\left\{(\boldsymbol{X} \perp \boldsymbol{Y} \mid \boldsymbol{Z}): \operatorname{sep}_{\mathcal{H}}(\boldsymbol{X} ; \boldsymbol{Y} \mid \boldsymbol{Z})\right\}
$$&lt;/p&gt;
&lt;p&gt;We prove the soundness and completeness of definition 4.9. For definition 4.9, the soundness and completeness are defined as follows:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;If we find that two nodes $X$ and $Y$ are d-separated given some $Z$, then we are guaranteed that they are, in fact, conditionally independent given $Z$.&lt;/li&gt;
&lt;li&gt;D-separation detects all possible independencies. More precisely, if we have that two variables $X$ and $Y$ are independent given $Z$, then they are d-separated.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Before we proof the soundness, we know that there is a Gibbs distribution $\mathcal{P}$ over $\mathcal{X}$ factorizes over $\mathcal{H}$ can be expressed by the Markov network $\mathcal{H}$. Let $\boldsymbol{X}, \boldsymbol{Y}, \boldsymbol{Z}$ be any three disjoint subsets in $\mathcal{X}$ such that $\boldsymbol{Z}$ separates $\boldsymbol{X}$ and $\boldsymbol{Y}$ in $\mathcal{H}$. We want to show that $P \models(\boldsymbol{X} \perp \boldsymbol{Y} \mid \boldsymbol{Z})$.&lt;/p&gt;
&lt;p&gt;We start by considering the case where $\boldsymbol{X} \cup \boldsymbol{Y} \cup \boldsymbol{Z}=\mathcal{X} .$ As $\boldsymbol{Z}$ separates $\boldsymbol{X}$ from $\boldsymbol{Y}$, there are no direct edges between $\boldsymbol{X}$ and $\boldsymbol{Y}$. Hence, any clique in $\mathcal{H}$ is fully contained either in $\boldsymbol{X} \cup \boldsymbol{Z}$ or in $\boldsymbol{Y} \cup \boldsymbol{Z}$. Let $\mathcal{I}_{\boldsymbol{X}}$ be the indexes of the set of cliques that are contained in $\boldsymbol{X} \cup \boldsymbol{Z}$, and let $\mathcal{I}_{Y}$ be the indexes of the remaining cliques. We know that&lt;/p&gt;
&lt;p&gt;$$
P\left(X_{1}, \ldots, X_{n}\right)=\frac{1}{Z} \prod_{i \in \mathcal{I}_{\boldsymbol{X}}} \phi_{i}\left(\boldsymbol{D}_{i}\right) \cdot \prod_{i \in \mathcal{I}_{\boldsymbol{Y}}} \phi_{i}\left(\boldsymbol{D}_{i}\right)
$$&lt;/p&gt;
&lt;p&gt;As we discussed, none of the factors in the first product involve any variable in $\boldsymbol{Y}$, and none in the second product involve any variable in $\boldsymbol{X}$. Hence, we can rewrite this product in the form:&lt;/p&gt;
&lt;p&gt;$$
P\left(X_{1}, \ldots, X_{n}\right)=\frac{1}{Z} f(\boldsymbol{X}, \boldsymbol{Z}) g(\boldsymbol{Y}, \boldsymbol{Z})
$$&lt;/p&gt;
&lt;p&gt;From this decomposition, the desired independence follows immediately (exercise 2.5). Now consider the case where $\boldsymbol{X} \cup \boldsymbol{Y} \cup \boldsymbol{Z} \subset \mathcal{X}$. Let $\boldsymbol{U}=\mathcal{X}-(\boldsymbol{X} \cup \boldsymbol{Y} \cup \boldsymbol{Z})$. We can
partition $\boldsymbol{U}$ into two disjoint sets $\boldsymbol{U}_{1}$ and $\boldsymbol{U}_{2}$ such that $\boldsymbol{Z}$ separates $\boldsymbol{X} \cup \boldsymbol{U}_{1}$ from $\boldsymbol{Y} \cup \boldsymbol{U}_{2}$ in $\mathcal{H}$. Using the preceding argument, we conclude that $P \models\left(\boldsymbol{X}, \boldsymbol{U}_{1} \perp \boldsymbol{Y}, \boldsymbol{U}_{2} \mid \boldsymbol{Z}\right)$. Using the
decomposition property $(\boldsymbol{X} \perp \boldsymbol{Y}, \boldsymbol{W} \mid \boldsymbol{Z}) \Longrightarrow(\boldsymbol{X} \perp \boldsymbol{Y} \mid \boldsymbol{Z})$ (equation 2.8), we conclude that $P \models(\boldsymbol{X} \perp \boldsymbol{Y} \mid \boldsymbol{Z})$.&lt;/p&gt;
&lt;p&gt;Let&amp;rsquo;s look at theorem 4.1&lt;/p&gt;
&lt;p&gt;Theorem 4.1:&lt;/p&gt;
&lt;p&gt;Let $P$ be a distribution over $\mathcal{X}$, and $\mathcal{H}$ a Markov network structure over $\mathcal{X}$. If $P$ is a Gibbs distribution that factorizes over $\mathcal{H}$, then $\mathcal{H}$ is an I-map for $P$.&lt;/p&gt;
&lt;p&gt;The proof of theorem 4.1 is the same as the proof of soundness, so, the authors say that &amp;ldquo;We first consider the analog to theorem 3.2, which asserts that a Gibbs distribution satisfies the independencies associated with the graph. In other words, this result states the soundness of the separation criterion.&amp;rdquo;&lt;/p&gt;
&lt;p&gt;I will talk about completeness in another post.&lt;/p&gt;
&lt;section class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Koller, D., &amp;amp; Friedman, N. (2009). Probabilistic graphical models: principles and techniques. MIT press. &lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:2&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Jordan, M. I. (2003). An introduction to probabilistic graphical models. &lt;a href=&#34;#fnref:2&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/section&gt;
</description>
    </item>
    
    <item>
      <title>Logic</title>
      <link>https://zhiyuanpeng.github.io/post/logic/</link>
      <pubDate>Tue, 04 May 2021 00:28:14 -0700</pubDate>
      <guid>https://zhiyuanpeng.github.io/post/logic/</guid>
      <description>&lt;style&gt;
body {
text-align: justify}
&lt;/style&gt;
&lt;h1 id=&#34;syntactic-consequence-vs-semantic-consequencehttpsphilosophystackexchangecoma72646&#34;&gt;&lt;a href=&#34;https://philosophy.stackexchange.com/a/72646&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Syntactic consequence vs Semantic consequence&lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;Syntactic consequence (A ⊢ B): B can be derived from A without even knowing if A is true. For example, &amp;lsquo;A implies B&amp;rsquo; can be converted to &amp;lsquo;notA or B&amp;rsquo;, regardless if &amp;lsquo;A implies B&amp;rsquo; was true or false. It&amp;rsquo;s a syntactic consequence. The model (all possible ways to get A to be true) doesn&amp;rsquo;t matter because truth doesn&amp;rsquo;t matter, because A being true doesn&amp;rsquo;t even matter.&lt;/p&gt;
&lt;p&gt;Semantic consequence (C |= D): Whenever C is true, then D is true.&lt;/p&gt;
&lt;p&gt;What is a model?: A model is just one combination of symbols that make the well-formed formula to be true: we have 3 possible models in A ∨ B, which are A=true,B=false, A=false,B=true and A=true,B=true. If whenever the left side (C) of semantic consequence is true, D is also true, then C semantically entails D.&lt;/p&gt;
&lt;h1 id=&#34;propositional-logic-and-first-order-logic&#34;&gt;Propositional Logic and First Order Logic&lt;/h1&gt;
&lt;p&gt;&lt;a href=&#34;chrome-extension://oemmndcbldboiebfnladdacbdfmadadm/https://courses.cs.cornell.edu/cs2800/2017sp/handouts/pass_tseng_discmath.pdf&#34;&gt;A Course in Discrete Structures&lt;/a&gt; gives basic explaintion of the two kinds of logic.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Ubuntu QA</title>
      <link>https://zhiyuanpeng.github.io/post/ubuntu-qa/</link>
      <pubDate>Mon, 05 Apr 2021 12:18:28 -0700</pubDate>
      <guid>https://zhiyuanpeng.github.io/post/ubuntu-qa/</guid>
      <description>&lt;style&gt;
body {
text-align: justify}
&lt;/style&gt;
&lt;h1 id=&#34;ubuntu-kernal-panic-when-reboot-or-poweroff&#34;&gt;Ubuntu kernal panic when reboot or poweroff&lt;/h1&gt;
&lt;pre&gt;&lt;code&gt;sudo -H gedit /etc/default/grub
GRUB_CMDLINE_LINUX_DEFAULT=&amp;quot;quiet initcall_blacklist=dw_i2c_init_driver&amp;quot;
sudo update-grub
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Finally, reboot the system.&lt;/p&gt;
&lt;h1 id=&#34;matlab&#34;&gt;Matlab&lt;/h1&gt;
&lt;h2 id=&#34;hidpi&#34;&gt;HIDPI&lt;/h2&gt;
&lt;pre&gt;&lt;code&gt;s = settings;s.matlab.desktop.DisplayScaleFactor
s.matlab.desktop.DisplayScaleFactor.PersonalValue = 2.5
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;matlab-luncher&#34;&gt;Matlab luncher&lt;/h2&gt;
&lt;pre&gt;&lt;code&gt;sudo apt-get install matlab-support
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Wowchemy Tips</title>
      <link>https://zhiyuanpeng.github.io/post/wowchemy-tips/</link>
      <pubDate>Mon, 05 Apr 2021 12:13:38 -0700</pubDate>
      <guid>https://zhiyuanpeng.github.io/post/wowchemy-tips/</guid>
      <description>&lt;style&gt;
body {
text-align: justify}
&lt;/style&gt;
&lt;h1 id=&#34;set-up-env-on-ununtu&#34;&gt;Set up Env on Ununtu&lt;/h1&gt;
&lt;h2 id=&#34;install-hugo&#34;&gt;Install Hugo&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/gohugoio/hugo/releases&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Download&lt;/a&gt; the &lt;strong&gt;Extended&lt;/strong&gt; installer for Debian (hugo_extended_&lt;VERSION&gt;_Linux-64bit.deb) and double-click the downloaded file to install with Ubuntu Software Center.&lt;/p&gt;
&lt;p&gt;Install Hugo’s Go dependency:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;sudo snap install --classic go
&lt;/code&gt;&lt;/pre&gt;
&lt;h1 id=&#34;create-a-new-posthttpswowchemycomdocscontentblog-posts&#34;&gt;&lt;a href=&#34;https://wowchemy.com/docs/content/blog-posts/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Create a new post&lt;/a&gt;&lt;/h1&gt;
&lt;pre&gt;&lt;code&gt;hugo new  --kind post post/my-article-name
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Use lower case for my-article-name and change the title in index.md&lt;/p&gt;
&lt;h1 id=&#34;update-the-website&#34;&gt;Update the Website&lt;/h1&gt;
&lt;pre&gt;&lt;code&gt;hugo
cd public
git add .
git commit -m &amp;quot;Build website&amp;quot;
git push origin master
cd ..
&lt;/code&gt;&lt;/pre&gt;
&lt;h1 id=&#34;update-the-publicationshttpswowchemycomdocscontentpublications&#34;&gt;&lt;a href=&#34;https://wowchemy.com/docs/content/publications/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Update the Publications&lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;Install the Academic&amp;rsquo;s admin tool:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;pip3 install -U academic
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If no pip3 installed, install pip3 first:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;sudo apt update
sudo apt install python3-pip
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Import the bibtex:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;academic import --bibtex &amp;lt;path_to_your/publications.bib&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;h1 id=&#34;special-characters-need-to-be-escaped&#34;&gt;Special Characters need to be Escaped&lt;/h1&gt;
&lt;p&gt;Wowchemy is bulit on Hugo which translates Markdown to html firstly, so, for latex math, there may be some errors during the translation. To use latex math smoothly in &lt;code&gt;.md&lt;/code&gt; file, some special characters need to be escaped. I summerize these characters as follows:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;{}_{} --&amp;gt; {}\_{}
\left or \right --&amp;gt; \left\ or \right\
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For multi line math:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;equation 1 \\ --&amp;gt; equation 1 \\\\
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If there are still some errors, go the the corresponding &lt;code&gt;.html&lt;/code&gt; file to find the error characters and escape them in &lt;code&gt;.md&lt;/code&gt; file.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Deploy a Website on EC2</title>
      <link>https://zhiyuanpeng.github.io/post/deploy-website-on-ec2/</link>
      <pubDate>Mon, 15 Feb 2021 21:10:42 -0800</pubDate>
      <guid>https://zhiyuanpeng.github.io/post/deploy-website-on-ec2/</guid>
      <description>&lt;style&gt;
body {
text-align: justify}
&lt;/style&gt;
&lt;h1 id=&#34;install-packages&#34;&gt;Install Packages&lt;/h1&gt;
&lt;p&gt;Use Anaconda to create a python3 environment, then, use the following commands to install apache2 and wsgi&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;sudo apt update
sudo apt install apache2
sudo apt-get install libapache2-mod-wsgi-py3
&lt;/code&gt;&lt;/pre&gt;
&lt;h1 id=&#34;configure-site&#34;&gt;Configure Site&lt;/h1&gt;
&lt;pre&gt;&lt;code&gt;sudo ln -sT /project/path/of/website /var/www/html/website
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Link the project to the folder under &lt;code&gt;/var/www/html&lt;/code&gt;. &lt;code&gt;/var/log/apache2/error.log&lt;/code&gt; can be used to debug the website.&lt;/p&gt;
&lt;h1 id=&#34;configure-ssl&#34;&gt;Configure SSL&lt;/h1&gt;
&lt;p&gt;First open ssl use the following command.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;sudo a2enmod ssl
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Then edit the /etc/apache2/site-enables/.conf like:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;&amp;lt;VirtualHost *:443&amp;gt;
        # The ServerName directive sets the request scheme, hostname and port that
        # the server uses to identify itself. This is used when creating
        # redirection URLs. In the context of virtual hosts, the ServerName
        # specifies what hostname must appear in the request&#39;s Host: header to
        # match this virtual host. For the default virtual host (this file) this
        # value is not decisive as it is used as a last resort host regardless.
        # However, you must set it for any further virtual host explicitly.
        #ServerName www.example.com

        ServerAdmin webmaster@localhost
        ServerName https://semanticsearch.site
        ServerAlias semanticsearch.site
        DocumentRoot /var/www/html
        SSLEngine on
        SSLCertificateFile /home/ubuntu/SSL/5191072_www.semanticsearch.site_public.crt
        SSLCertificateKeyFile /home/ubuntu/SSL/5191072_www.semanticsearch.site.key
        SSLCertificateChainFile /home/ubuntu/SSL/5191072_www.semanticsearch.site_chain.crt

        WSGIDaemonProcess SSApp python-path=/home/ubuntu/anaconda3/envs/py38/lib/python3.8/site-packages
        WSGIScriptAlias / /var/www/html/SSApp/ssapp.wsgi
        WSGIProcessGroup SSApp
        WSGIApplicationGroup %{GLOBAL}
        &amp;lt;Directory /var/www/html/SSApp&amp;gt;
                #WSGIProcessGroup SSApp
                #WSGIApplicationGroup %{GLOBAL}
                Order allow,deny
                Allow from all
        &amp;lt;/Directory&amp;gt;


        # Available loglevels: trace8, ..., trace1, debug, info, notice, warn,
        # error, crit, alert, emerg.
        # It is also possible to configure the loglevel for particular
        # modules, e.g.
        #LogLevel info ssl:warn

        ErrorLog ${APACHE_LOG_DIR}/error.log
        CustomLog ${APACHE_LOG_DIR}/access.log combined

        # For most configuration files from conf-available/, which are
        # enabled or disabled at a global level, it is possible to
        # include a line for only one particular virtual host. For example the
        # following line enables the CGI configuration for this host only
        # after it has been globally disabled with &amp;quot;a2disconf&amp;quot;.
        #Include conf-available/serve-cgi-bin.conf
&amp;lt;/VirtualHost&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;use &lt;code&gt;apachectl configtest&lt;/code&gt; to check the syntax of the conf file and then restart the apache service &lt;code&gt;sudo service apache2 restart&lt;/code&gt;&lt;/p&gt;
&lt;h1 id=&#34;change-the-permission-of-the-folder&#34;&gt;Change the Permission of the Folder&lt;/h1&gt;
&lt;p&gt;I use the following bash file to deloy the website on server.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;git clone git@github.com:SemanticSearching/SSApp.git
cd /home/ubuntu/proj/SSApp
git checkout dev
sudo chown -vR :ssapp /home/ubuntu/proj/SSApp/
sudo chmod -vR g+w /home/ubuntu/proj/SSApp/
sudo service apache2 restart
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
  </channel>
</rss>
